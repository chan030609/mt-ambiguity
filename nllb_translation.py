# -*- coding: utf-8 -*-
"""nllb translation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DXm6JB4BHIZ1S76uvqedgh8XzCfnICxc
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab Notebooks/mt-ambiguitiy

!pip install -q transformers

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from tqdm import tqdm
import warnings
import pandas as pd
import torch
import time
import numpy as np
warnings.filterwarnings("ignore")
device = "cuda:0" if torch.cuda.is_available() else "cpu"

tokenizer = AutoTokenizer.from_pretrained("facebook/nllb-200-distilled-600M")
model = AutoModelForSeq2SeqLM.from_pretrained("facebook/nllb-200-distilled-600M").to(device)

"""### Preprocessing"""

project = 'subdf_gpt3_prompt_v7'
subdf = pd.read_csv(project + '.csv')
# subdf = df[:1000]
subdf

"""### Batch Translation"""

### TWICE AS SLOW AS BATCH ###
# def translate(x):
#     inputs = tokenizer(x, return_tensors='pt').to(device)
#     translated_tokens = model.generate(
#         **inputs, forced_bos_token_id=tokenizer.lang_code_to_id["kor_Hang"]
#     )
#     res = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]
#     return res

def translate_batch(x, lang_code):
    inputs = tokenizer(x, return_tensors='pt', padding=True).to(device)
    translated_tokens = model.generate(
        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[lang_code]
    )
    res = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)
    return res

lang_codes = ["kor_Hang", "fra_Latn", "heb_Hebr", "zho_Hans", "yor_Latn"]
batch_size = 40

start = time.time()

for lang_code in lang_codes:
    subdf[lang_code + "_idiom"] = ""
    subdf[lang_code + "_phrase"] = ""
    subdf[lang_code + "_sentence"] = ""

for i in tqdm(range(0, len(subdf), batch_size)):

    i_end = min(len(subdf), i + batch_size)

    for lang_code in lang_codes:
        subdf[lang_code + "_idiom"][i: i_end] = translate_batch(subdf['idiom'][i: i_end].tolist(), lang_code)
        subdf[lang_code + "_phrase"][i: i_end] = translate_batch(subdf['phrase'][i: i_end].tolist(), lang_code)
        subdf[lang_code + "_sentence"][i: i_end] = translate_batch(subdf['sentence'][i: i_end].tolist(), lang_code)

end = time.time()
print(f"\nCompletion in {(end - start)} seconds")

"""### Examination"""

subdf.to_csv(project + f'_{len(lang_codes)}lang.csv', index=False)

subdf

